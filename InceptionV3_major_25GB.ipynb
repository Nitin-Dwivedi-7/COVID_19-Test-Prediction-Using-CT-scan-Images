{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InceptionV3_major_25GB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nitin-Dwivedi-7/COVID_19-Test-Prediction-Using-CT-scan-Images/blob/main/InceptionV3_major_25GB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cbgwZWWfWpp"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAb77yZ9fzMG",
        "outputId": "edd50837-ea8f-4c4c-b40b-91ecb31dd226",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pafL7Li0jyXW"
      },
      "source": [
        "#import Keras packages\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.preprocessing.image import load_img\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "from keras import applications\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "from keras.utils import get_file"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JDkZP5cDs03"
      },
      "source": [
        "import pickle \n",
        "file = \"/content/drive/My Drive/data_5K.pkl\"\n",
        "f_o=open(file,\"rb\")\n",
        "data=pickle.load(f_o)\n",
        "f_o.close()\n",
        "file= \"/content/drive/My Drive/labels_5k.pkl\"\n",
        "f_o=open(file,\"rb\")\n",
        "labels=pickle.load(f_o)\n",
        "f_o.close()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBTLDXpaq1_8"
      },
      "source": [
        "data = np.array(data)\n",
        "labels = np.array(labels)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVgA2wbMq4Aa"
      },
      "source": [
        "img_width, img_height = 256, 256        # Resolution of inputs\n",
        "#train_data_dir = \"train\"           # Folder of train samples\n",
        "#validation_data_dir = \"val\" # Folder of validation samples44\n",
        "#nb_train_samples = 10000                # Number of train samples\n",
        "#nb_validation_samples = 9500            # Number of validation samples\n",
        "batch_size = 64                        # Batch size\n",
        "epochs = 20                # Maximum number of epochs"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfQ1oymIq7jX",
        "outputId": "7dde5f80-4640-4165-e9a4-464a2d9be2e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Load InceptionV3\n",
        "model=applications.inception_v3.InceptionV3(weights=\"imagenet\", include_top=False, input_shape=(img_width, img_height, 3))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGPz5cc2rM0z"
      },
      "source": [
        "# Freeze first 15 layers\n",
        "for layer in model.layers[:45]:\n",
        "\tlayer.trainable = False\n",
        "for layer in model.layers[45:]:\n",
        "   layer.trainable = True"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YfNx71vrQpS"
      },
      "source": [
        "x = model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(1024, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(2, activation=\"softmax\")(x) # 4-way softmax classifier at the end\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CW3A0PE0rStQ"
      },
      "source": [
        "#nb_train_samples = 2543                # Number of train samples\n",
        "#nb_validation_samples = 2261            # Number of validation samples\n",
        "\n",
        "# Initializing the CNN\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJH_xFyprVF1"
      },
      "source": [
        "from keras.utils.np_utils import to_categorical   \n",
        "\n",
        "categorical_labels = to_categorical(labels, num_classes=2)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#X_train1, X_test0, ytrain1, ytest0 = train_test_split(data, categorical_labels, test_size=0.1,\n",
        "                                                    #random_state=random.randint(0,100))\n",
        "X_train1 = data\n",
        "ytrain1 = categorical_labels\n",
        "\n",
        "for index in range(10):\n",
        "  classifier = Model(model.input,predictions)\n",
        "  classifier.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.SGD(lr=1e-3, momentum=0.9), metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "X_train, X_test1, ytrain, ytest1 = train_test_split(X_train1, ytrain1, test_size=0.1,\n",
        "                                                    random_state=random.randint(0,100))\n",
        "X_val, X_test, yval, ytest = train_test_split(X_test1, ytest1, test_size=0.5,\n",
        "                                                    random_state=random.randint(0,100))\n",
        "    \n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPhxrokdrZBY",
        "outputId": "6f5458c7-5ffc-452c-d2d5-5fe1a2d442e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "    \n",
        "train_datagen = ImageDataGenerator(\n",
        "            rescale=1./255,\n",
        "            shear_range=0.2,\n",
        "            zoom_range=0.2,\n",
        "            horizontal_flip=True)\n",
        "    \n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    \n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    \n",
        "training_set = train_datagen.flow(\n",
        "            X_train, ytrain,\n",
        "            batch_size=64)\n",
        "    \n",
        "val_set = val_datagen.flow(\n",
        "            X_val, yval,\n",
        "            batch_size=64)\n",
        "    \n",
        "test_set = test_datagen.flow(\n",
        "            X_test, ytest,\n",
        "            batch_size=64)\n",
        "    \n",
        "X, y = test_set.next()\n",
        "    \n",
        "classifier.fit_generator(\n",
        "            training_set,\n",
        "            steps_per_epoch=20,\n",
        "            epochs=epochs,\n",
        "            validation_data=val_set,\n",
        "            validation_steps=100)\n",
        "    \n",
        "    #w_file = 'Wilson_vgg16_model_weights_k10.h5'\n",
        "    #classifier.save_weights(w_file)\n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-10-8e5f3ef987a6>:32: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/20\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.5785 - accuracy: 0.7391WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 100 batches). You may need to use the repeat() function when building your dataset.\n",
            "20/20 [==============================] - 18s 887ms/step - loss: 0.5785 - accuracy: 0.7391 - val_loss: 0.4707 - val_accuracy: 0.8068\n",
            "Epoch 2/20\n",
            "20/20 [==============================] - 16s 789ms/step - loss: 0.1667 - accuracy: 0.9336\n",
            "Epoch 3/20\n",
            "20/20 [==============================] - 16s 785ms/step - loss: 0.0776 - accuracy: 0.9758\n",
            "Epoch 4/20\n",
            "20/20 [==============================] - 16s 783ms/step - loss: 0.0895 - accuracy: 0.9742\n",
            "Epoch 5/20\n",
            "20/20 [==============================] - 16s 785ms/step - loss: 0.0545 - accuracy: 0.9836\n",
            "Epoch 6/20\n",
            "20/20 [==============================] - 16s 785ms/step - loss: 0.0561 - accuracy: 0.9828\n",
            "Epoch 7/20\n",
            "20/20 [==============================] - 16s 778ms/step - loss: 0.0334 - accuracy: 0.9891\n",
            "Epoch 8/20\n",
            "20/20 [==============================] - 16s 776ms/step - loss: 0.0325 - accuracy: 0.9898\n",
            "Epoch 9/20\n",
            "20/20 [==============================] - 16s 782ms/step - loss: 0.0299 - accuracy: 0.9914\n",
            "Epoch 10/20\n",
            "20/20 [==============================] - 15s 772ms/step - loss: 0.0227 - accuracy: 0.9930\n",
            "Epoch 11/20\n",
            "20/20 [==============================] - 16s 791ms/step - loss: 0.0157 - accuracy: 0.9953\n",
            "Epoch 12/20\n",
            "20/20 [==============================] - 15s 762ms/step - loss: 0.0124 - accuracy: 0.9937\n",
            "Epoch 13/20\n",
            "20/20 [==============================] - 15s 773ms/step - loss: 0.0131 - accuracy: 0.9961\n",
            "Epoch 14/20\n",
            "20/20 [==============================] - 15s 761ms/step - loss: 0.0158 - accuracy: 0.9945\n",
            "Epoch 15/20\n",
            "20/20 [==============================] - 15s 770ms/step - loss: 0.0072 - accuracy: 0.9984\n",
            "Epoch 16/20\n",
            "20/20 [==============================] - 15s 758ms/step - loss: 0.0130 - accuracy: 0.9961\n",
            "Epoch 17/20\n",
            "20/20 [==============================] - 15s 759ms/step - loss: 0.0032 - accuracy: 0.9992\n",
            "Epoch 18/20\n",
            "20/20 [==============================] - 15s 758ms/step - loss: 0.0122 - accuracy: 0.9992\n",
            "Epoch 19/20\n",
            "20/20 [==============================] - 15s 758ms/step - loss: 0.0044 - accuracy: 0.9992\n",
            "Epoch 20/20\n",
            "20/20 [==============================] - 15s 752ms/step - loss: 0.0112 - accuracy: 0.9968\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8c1bcc3be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAfTyf7YzGCZ",
        "outputId": "936f8eb0-de4a-4818-951e-8db31335d1a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "arr = classifier.evaluate(X,y)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - ETA: 0s - loss: 1.0888e-04 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0151s vs `on_test_batch_end` time: 0.0467s). Check your callbacks.\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 1.0888e-04 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfNSz9h2zIkT",
        "outputId": "3b13dfbe-dce5-481b-e45d-a666bf1ac9f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(arr)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.00010888213000725955, 1.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_bpNxra6l8W"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6kxGURXrcDw",
        "outputId": "53785c53-b49d-4981-a503-b5fb66899405",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "\n",
        "arr = classifier.predict(X)\n",
        "arr = np.argmax(arr, axis=1)\n",
        "\n",
        "print(arr)\n",
        "print(y)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 1 0 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1 0 1\n",
            " 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0]\n",
            "[[1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eG860e3Fy7j8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
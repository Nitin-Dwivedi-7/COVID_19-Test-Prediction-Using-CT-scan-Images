{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg19_major_25GB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nitin-Dwivedi-7/COVID_19-Test-Prediction-Using-CT-scan-Images/blob/main/vgg19_major_25GB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cbgwZWWfWpp"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAb77yZ9fzMG",
        "outputId": "e92b928f-d803-4573-e0c5-f8e7f81ff3e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pafL7Li0jyXW"
      },
      "source": [
        "#import Keras packages\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.preprocessing.image import load_img\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "from keras import applications\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "from keras.utils import get_file"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JDkZP5cDs03"
      },
      "source": [
        "import pickle \n",
        "file = \"/content/drive/My Drive/data_5K.pkl\"\n",
        "f_o=open(file,\"rb\")\n",
        "data=pickle.load(f_o)\n",
        "f_o.close()\n",
        "file= \"/content/drive/My Drive/labels_5k.pkl\"\n",
        "f_o=open(file,\"rb\")\n",
        "labels=pickle.load(f_o)\n",
        "f_o.close()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBTLDXpaq1_8"
      },
      "source": [
        "data = np.array(data)\n",
        "labels = np.array(labels)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVgA2wbMq4Aa"
      },
      "source": [
        "img_width, img_height = 256, 256        # Resolution of inputs\n",
        "#train_data_dir = \"train\"           # Folder of train samples\n",
        "#validation_data_dir = \"val\" # Folder of validation samples44\n",
        "#nb_train_samples = 10000                # Number of train samples\n",
        "#nb_validation_samples = 9500            # Number of validation samples\n",
        "batch_size = 64                        # Batch size\n",
        "epochs = 20                # Maximum number of epochs"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfQ1oymIq7jX",
        "outputId": "cf1d2cbf-dbc5-4752-9f59-abbad277eeeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vgg19 = keras.applications.vgg19.VGG19(\n",
        "  weights='imagenet',\n",
        "  include_top=False,\n",
        "  input_shape=(img_height, img_width, 3))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGPz5cc2rM0z"
      },
      "source": [
        "for layer in vgg19.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YfNx71vrQpS"
      },
      "source": [
        "model = Sequential(layers=vgg19.layers)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtiBQtyvIZYR"
      },
      "source": [
        "classifier = model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CW3A0PE0rStQ"
      },
      "source": [
        "nb_train_samples = 2543                # Number of train samples\n",
        "nb_validation_samples = 2261            # Number of validation samples\n",
        "\n",
        "# Initializing the CNN\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJH_xFyprVF1"
      },
      "source": [
        "from keras.utils.np_utils import to_categorical   \n",
        "\n",
        "categorical_labels = to_categorical(labels, num_classes=2)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#X_train1, X_test0, ytrain1, ytest0 = train_test_split(data, categorical_labels, test_size=0.1,\n",
        "                                                    #random_state=random.randint(0,100))\n",
        "X_train1 = data\n",
        "ytrain1 = categorical_labels\n",
        "\n",
        "for index in range(10):\n",
        "  #classifier = Model(model.input,predictions)\n",
        "  classifier.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.SGD(lr=1e-3, momentum=0.9), metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "X_train, X_test1, ytrain, ytest1 = train_test_split(X_train1, ytrain1, test_size=0.1,\n",
        "                                                    random_state=random.randint(0,100))\n",
        "X_val, X_test, yval, ytest = train_test_split(X_test1, ytest1, test_size=0.5,\n",
        "                                                    random_state=random.randint(0,100))\n",
        "    \n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPhxrokdrZBY",
        "outputId": "b69c4875-0568-46e2-9ecc-b899dfd65940",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "    \n",
        "train_datagen = ImageDataGenerator(\n",
        "            rescale=1./255,\n",
        "            shear_range=0.2,\n",
        "            zoom_range=0.2,\n",
        "            horizontal_flip=True)\n",
        "    \n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    \n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    \n",
        "training_set = train_datagen.flow(\n",
        "            X_train, ytrain,\n",
        "            batch_size=64)\n",
        "    \n",
        "val_set = val_datagen.flow(\n",
        "            X_val, yval,\n",
        "            batch_size=64)\n",
        "    \n",
        "test_set = test_datagen.flow(\n",
        "            X_test, ytest,\n",
        "            batch_size=64)\n",
        "    \n",
        "X, y = test_set.next()\n",
        "    \n",
        "classifier.fit_generator(\n",
        "            training_set,\n",
        "            steps_per_epoch=20,\n",
        "            epochs=20,\n",
        "            validation_data=val_set,\n",
        "            validation_steps=100)\n",
        "    \n",
        "    #w_file = 'Wilson_vgg16_model_weights_k10.h5'\n",
        "    #classifier.save_weights(w_file)\n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-13-f9d3d78a6ee7>:32: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/20\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.4177 - accuracy: 0.8031WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 100 batches). You may need to use the repeat() function when building your dataset.\n",
            "20/20 [==============================] - 18s 890ms/step - loss: 0.4177 - accuracy: 0.8031 - val_loss: 0.1574 - val_accuracy: 0.9477\n",
            "Epoch 2/20\n",
            "20/20 [==============================] - 16s 803ms/step - loss: 0.1719 - accuracy: 0.9453\n",
            "Epoch 3/20\n",
            "20/20 [==============================] - 16s 784ms/step - loss: 0.1381 - accuracy: 0.9555\n",
            "Epoch 4/20\n",
            "20/20 [==============================] - 16s 798ms/step - loss: 0.1186 - accuracy: 0.9555\n",
            "Epoch 5/20\n",
            "20/20 [==============================] - 16s 808ms/step - loss: 0.1048 - accuracy: 0.9711\n",
            "Epoch 6/20\n",
            "20/20 [==============================] - 16s 809ms/step - loss: 0.0967 - accuracy: 0.9688\n",
            "Epoch 7/20\n",
            "20/20 [==============================] - 16s 789ms/step - loss: 0.1196 - accuracy: 0.9539\n",
            "Epoch 8/20\n",
            "20/20 [==============================] - 16s 792ms/step - loss: 0.0960 - accuracy: 0.9688\n",
            "Epoch 9/20\n",
            "20/20 [==============================] - 16s 787ms/step - loss: 0.0620 - accuracy: 0.9789\n",
            "Epoch 10/20\n",
            "20/20 [==============================] - 16s 779ms/step - loss: 0.0699 - accuracy: 0.9797\n",
            "Epoch 11/20\n",
            "20/20 [==============================] - 16s 804ms/step - loss: 0.0601 - accuracy: 0.9795\n",
            "Epoch 12/20\n",
            "20/20 [==============================] - 16s 782ms/step - loss: 0.0779 - accuracy: 0.9719\n",
            "Epoch 13/20\n",
            "20/20 [==============================] - 16s 801ms/step - loss: 0.0563 - accuracy: 0.9797\n",
            "Epoch 14/20\n",
            "20/20 [==============================] - 16s 788ms/step - loss: 0.0639 - accuracy: 0.9805\n",
            "Epoch 15/20\n",
            "20/20 [==============================] - 16s 800ms/step - loss: 0.0464 - accuracy: 0.9867\n",
            "Epoch 16/20\n",
            "20/20 [==============================] - 15s 774ms/step - loss: 0.0758 - accuracy: 0.9701\n",
            "Epoch 17/20\n",
            "20/20 [==============================] - 15s 773ms/step - loss: 0.0549 - accuracy: 0.9789\n",
            "Epoch 18/20\n",
            "20/20 [==============================] - 15s 768ms/step - loss: 0.0517 - accuracy: 0.9836\n",
            "Epoch 19/20\n",
            "20/20 [==============================] - 15s 764ms/step - loss: 0.0473 - accuracy: 0.9836\n",
            "Epoch 20/20\n",
            "20/20 [==============================] - 15s 767ms/step - loss: 0.0355 - accuracy: 0.9905\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff7bd9504a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAfTyf7YzGCZ",
        "outputId": "d856aa2e-60d1-469a-8085-a63d7ea85fbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "arr = classifier.evaluate(X,y)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0086s vs `on_test_batch_end` time: 0.0824s). Check your callbacks.\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0077 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfNSz9h2zIkT",
        "outputId": "b269cb17-17ec-49cb-a36c-c1db281fee6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(arr)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.007655028253793716, 1.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_bpNxra6l8W"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6kxGURXrcDw",
        "outputId": "9fc907f9-2015-4b6e-905d-cf80456918bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "\n",
        "arr = classifier.predict(X)\n",
        "arr = np.argmax(arr, axis=1)\n",
        "\n",
        "print(arr)\n",
        "print(y)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1 1 0 0 1 0 0 0 0 1\n",
            " 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 1]\n",
            "[[1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lDFIy2VEhGz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG16_major_25GB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nitin-Dwivedi-7/COVID_19-Test-Prediction-Using-CT-scan-Images/blob/main/VGG16_major_25GB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cbgwZWWfWpp"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAb77yZ9fzMG",
        "outputId": "b5ef9761-efac-4797-a00c-e20aaccd7a42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pafL7Li0jyXW"
      },
      "source": [
        "#import Keras packages\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.preprocessing.image import load_img\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "from keras import applications\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "from keras.utils import get_file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JDkZP5cDs03"
      },
      "source": [
        "import pickle \n",
        "file = \"/content/drive/My Drive/data_5K.pkl\"\n",
        "f_o=open(file,\"rb\")\n",
        "data=pickle.load(f_o)\n",
        "f_o.close()\n",
        "file= \"/content/drive/My Drive/labels_5k.pkl\"\n",
        "f_o=open(file,\"rb\")\n",
        "labels=pickle.load(f_o)\n",
        "f_o.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBTLDXpaq1_8"
      },
      "source": [
        "data = np.array(data)\n",
        "labels = np.array(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVgA2wbMq4Aa"
      },
      "source": [
        "img_width, img_height = 256, 256        # Resolution of inputs\n",
        "#train_data_dir = \"train\"           # Folder of train samples\n",
        "#validation_data_dir = \"val\" # Folder of validation samples44\n",
        "#nb_train_samples = 10000                # Number of train samples\n",
        "#nb_validation_samples = 9500            # Number of validation samples\n",
        "batch_size = 64                        # Batch size\n",
        "epochs = 20                # Maximum number of epochs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfQ1oymIq7jX",
        "outputId": "7bfec2d0-7769-45e8-cae2-55294c60245d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#VGG 16\n",
        "model=applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGPz5cc2rM0z"
      },
      "source": [
        "# Freeze first 15 layers\n",
        "for layer in model.layers[:45]:\n",
        "\tlayer.trainable = False\n",
        "for layer in model.layers[45:]:\n",
        "   layer.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YfNx71vrQpS"
      },
      "source": [
        "x = model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(1024, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(2, activation=\"softmax\")(x) # 4-way softmax classifier at the end\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CW3A0PE0rStQ"
      },
      "source": [
        "nb_train_samples = 2543                # Number of train samples\n",
        "nb_validation_samples = 2261            # Number of validation samples\n",
        "\n",
        "# Initializing the CNN\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJH_xFyprVF1"
      },
      "source": [
        "from keras.utils.np_utils import to_categorical   \n",
        "\n",
        "categorical_labels = to_categorical(labels, num_classes=2)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#X_train1, X_test0, ytrain1, ytest0 = train_test_split(data, categorical_labels, test_size=0.1,\n",
        "                                                    #random_state=random.randint(0,100))\n",
        "X_train1 = data\n",
        "ytrain1 = categorical_labels\n",
        "\n",
        "for index in range(10):\n",
        "  classifier = Model(model.input,predictions)\n",
        "  classifier.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.SGD(lr=1e-3, momentum=0.9), metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "X_train, X_test1, ytrain, ytest1 = train_test_split(X_train1, ytrain1, test_size=0.1,\n",
        "                                                    random_state=random.randint(0,100))\n",
        "X_val, X_test, yval, ytest = train_test_split(X_test1, ytest1, test_size=0.5,\n",
        "                                                    random_state=random.randint(0,100))\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPhxrokdrZBY",
        "outputId": "516b4e9a-6905-4a6b-a2b0-6ed7905be49f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "    \n",
        "train_datagen = ImageDataGenerator(\n",
        "            rescale=1./255,\n",
        "            shear_range=0.2,\n",
        "            zoom_range=0.2,\n",
        "            horizontal_flip=True)\n",
        "    \n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    \n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    \n",
        "training_set = train_datagen.flow(\n",
        "            X_train, ytrain,\n",
        "            batch_size=64)\n",
        "    \n",
        "val_set = val_datagen.flow(\n",
        "            X_val, yval,\n",
        "            batch_size=64)\n",
        "    \n",
        "test_set = test_datagen.flow(\n",
        "            X_test, ytest,\n",
        "            batch_size=64)\n",
        "    \n",
        "X, y = test_set.next()\n",
        "    \n",
        "classifier.fit_generator(\n",
        "            training_set,\n",
        "            steps_per_epoch=20,\n",
        "            epochs=20,\n",
        "            validation_data=val_set,\n",
        "            validation_steps=100)\n",
        "    \n",
        "    #w_file = 'Wilson_vgg16_model_weights_k10.h5'\n",
        "    #classifier.save_weights(w_file)\n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-11-f9d3d78a6ee7>:32: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/20\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.7128 - accuracy: 0.6148WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 100 batches). You may need to use the repeat() function when building your dataset.\n",
            "20/20 [==============================] - 16s 821ms/step - loss: 0.7128 - accuracy: 0.6148 - val_loss: 0.3413 - val_accuracy: 0.9054\n",
            "Epoch 2/20\n",
            "20/20 [==============================] - 15s 736ms/step - loss: 0.5522 - accuracy: 0.7250\n",
            "Epoch 3/20\n",
            "20/20 [==============================] - 14s 720ms/step - loss: 0.3435 - accuracy: 0.8562\n",
            "Epoch 4/20\n",
            "20/20 [==============================] - 15s 732ms/step - loss: 0.2820 - accuracy: 0.8828\n",
            "Epoch 5/20\n",
            "20/20 [==============================] - 14s 720ms/step - loss: 0.2466 - accuracy: 0.9094\n",
            "Epoch 6/20\n",
            "20/20 [==============================] - 14s 719ms/step - loss: 0.2046 - accuracy: 0.9289\n",
            "Epoch 7/20\n",
            "20/20 [==============================] - 15s 727ms/step - loss: 0.1723 - accuracy: 0.9422\n",
            "Epoch 8/20\n",
            "20/20 [==============================] - 14s 719ms/step - loss: 0.1842 - accuracy: 0.9281\n",
            "Epoch 9/20\n",
            "20/20 [==============================] - 15s 732ms/step - loss: 0.1709 - accuracy: 0.9398\n",
            "Epoch 10/20\n",
            "20/20 [==============================] - 15s 736ms/step - loss: 0.1514 - accuracy: 0.9480\n",
            "Epoch 11/20\n",
            "20/20 [==============================] - 14s 717ms/step - loss: 0.1092 - accuracy: 0.9680\n",
            "Epoch 12/20\n",
            "20/20 [==============================] - 15s 730ms/step - loss: 0.1787 - accuracy: 0.9305\n",
            "Epoch 13/20\n",
            "20/20 [==============================] - 15s 729ms/step - loss: 0.1541 - accuracy: 0.9414\n",
            "Epoch 14/20\n",
            "20/20 [==============================] - 14s 712ms/step - loss: 0.1508 - accuracy: 0.9488\n",
            "Epoch 15/20\n",
            "20/20 [==============================] - 14s 705ms/step - loss: 0.1113 - accuracy: 0.9630\n",
            "Epoch 16/20\n",
            "20/20 [==============================] - 14s 714ms/step - loss: 0.1398 - accuracy: 0.9500\n",
            "Epoch 17/20\n",
            "20/20 [==============================] - 14s 717ms/step - loss: 0.1154 - accuracy: 0.9547\n",
            "Epoch 18/20\n",
            "20/20 [==============================] - 14s 708ms/step - loss: 0.1243 - accuracy: 0.9535\n",
            "Epoch 19/20\n",
            "20/20 [==============================] - 14s 710ms/step - loss: 0.1197 - accuracy: 0.9617\n",
            "Epoch 20/20\n",
            "20/20 [==============================] - 14s 711ms/step - loss: 0.0975 - accuracy: 0.9695\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdfe9a329e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAfTyf7YzGCZ",
        "outputId": "bd19c070-3739-4f87-be19-89061c77a9dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "arr = classifier.evaluate(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - ETA: 0s - loss: 0.0280 - accuracy: 0.9844WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0081s vs `on_test_batch_end` time: 0.0688s). Check your callbacks.\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0280 - accuracy: 0.9844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfNSz9h2zIkT",
        "outputId": "76d6e158-4bb3-4625-bc23-6500c10273c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(arr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.027987835928797722, 0.984375]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_bpNxra6l8W"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6kxGURXrcDw",
        "outputId": "24b76810-8d78-4a1c-e817-7cd2805401dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "\n",
        "arr = classifier.predict(X)\n",
        "arr = np.argmax(arr, axis=1)\n",
        "\n",
        "print(arr)\n",
        "print(y)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 0 1 1 0 0 0 1 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 0 0 1 0 0\n",
            " 1 1 1 1 0 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0]\n",
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lDFIy2VEhGz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}